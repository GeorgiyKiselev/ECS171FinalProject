{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!unzip data_evensplit.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "APY3daNuXOap"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "n3zpzRaUWgP0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from glob import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "from operator import add\n",
        "from tqdm import tqdm\n",
        "import imageio\n",
        "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score, roc_auc_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "T1hRlp8JWgP4"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def train_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "m0z157ydWgP6"
      },
      "outputs": [],
      "source": [
        "class DriveDataset(Dataset):\n",
        "    def __init__(self, images_path, masks_path):\n",
        "        self.images_path = images_path\n",
        "        self.masks_path = masks_path\n",
        "        self.n_samples = len(images_path)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = cv2.imread(self.images_path[index], cv2.IMREAD_GRAYSCALE)\n",
        "        image = image/255.0\n",
        "        image = np.expand_dims(image, axis=0)\n",
        "        image = image.astype(np.float32)\n",
        "        image = torch.from_numpy(image)\n",
        "\n",
        "        mask = cv2.imread(self.masks_path[index], cv2.IMREAD_GRAYSCALE)\n",
        "        mask = mask/255.0\n",
        "        mask = np.expand_dims(mask, axis=0)\n",
        "        mask = mask.astype(np.float32)\n",
        "        mask = torch.from_numpy(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "IT-Zif2iWgP7"
      },
      "outputs": [],
      "source": [
        "class Conv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.drop = nn.Dropout(0.2)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.drop(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Downs(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = Conv(in_channels, out_channels)\n",
        "        self.pool = nn.MaxPool2d((2, 2))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.conv(inputs)\n",
        "        p = self.pool(x)\n",
        "\n",
        "        return x, p\n",
        "\n",
        "class Ups(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2, padding=0)\n",
        "        self.conv = Conv(out_channels+out_channels, out_channels)\n",
        "\n",
        "    def forward(self, inputs, skip):\n",
        "        x = self.up(inputs)\n",
        "        x = torch.cat([x, skip], axis=1)\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class UNET(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.down1 = Downs(1, 64)\n",
        "        self.down2 = Downs(64, 128)\n",
        "        self.down3 = Downs(128, 256)\n",
        "        self.down4 = Downs(256, 512)\n",
        "\n",
        "        self.bottleneck = Conv(512, 1024)\n",
        "\n",
        "        self.up1 = Ups(1024, 512)\n",
        "        self.up2 = Ups(512, 256)\n",
        "        self.up3 = Ups(256, 128)\n",
        "        self.up4 = Ups(128, 64)\n",
        "\n",
        "        self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        skip1, down1 = self.down1(inputs)\n",
        "        skip2, down2 = self.down2(down1)\n",
        "        skip3, down3 = self.down3(down2)\n",
        "        skip4, down4 = self.down4(down3)\n",
        "\n",
        "        b = self.bottleneck(down4)\n",
        "\n",
        "        up1 = self.up1(b, skip4)\n",
        "        up2 = self.up2(up1, skip3)\n",
        "        up3 = self.up3(up2, skip2)\n",
        "        up4 = self.up4(up3, skip1)\n",
        "\n",
        "        outputs = self.outputs(up4)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "\n",
        "        inputs = torch.sigmoid(inputs)\n",
        "\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        intersect = (inputs * targets).sum()\n",
        "        dice = (2.*intersect + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
        "\n",
        "        return 1 - dice\n",
        "\n",
        "class DiceBCELoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceBCELoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "\n",
        "        inputs = torch.sigmoid(inputs)\n",
        "\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        intersect = (inputs * targets).sum()\n",
        "        dice_loss = 1 - (2.*intersect + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
        "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
        "        Dice_BCE = BCE + dice_loss\n",
        "\n",
        "        return Dice_BCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "FjRvEEMAWgP9"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, optimizer, loss_fn, device):\n",
        "    epoch_loss = 0.0\n",
        "    model.train()\n",
        "    for x,y in loader:\n",
        "        x = x.to(device, dtype = torch.float32)\n",
        "        y = y.to(device, dtype = torch.float32)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(x)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    epoch_loss = epoch_loss/len(loader)\n",
        "    return epoch_loss\n",
        "\n",
        "def evaluate(model, loader, loss_fn, device):\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device, dtype=torch.float32)\n",
        "            y = y.to(device, dtype=torch.float32)\n",
        "\n",
        "            y_pred = model(x)\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        epoch_loss = epoch_loss/len(loader)\n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ0TyK7gWgQA",
        "outputId": "48abd772-5244-4513-b796-5ac2bc55360d",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss has improved from inf to 1.3024\n",
            "Epoch: 01 | Epoch Time: 0m 25s\n",
            "\tTrain Loss: 1.348\n",
            "\t Val. Loss: 1.302\n",
            "\n",
            "Validation loss has improved from 1.3024 to 1.0501\n",
            "Epoch: 02 | Epoch Time: 0m 26s\n",
            "\tTrain Loss: 1.120\n",
            "\t Val. Loss: 1.050\n",
            "\n",
            "Validation loss has improved from 1.0501 to 1.0163\n",
            "Epoch: 03 | Epoch Time: 0m 26s\n",
            "\tTrain Loss: 1.057\n",
            "\t Val. Loss: 1.016\n",
            "\n",
            "Validation loss has improved from 1.0163 to 0.9788\n",
            "Epoch: 04 | Epoch Time: 0m 26s\n",
            "\tTrain Loss: 1.014\n",
            "\t Val. Loss: 0.979\n",
            "\n",
            "Validation loss has improved from 0.9788 to 0.9475\n",
            "Epoch: 05 | Epoch Time: 0m 26s\n",
            "\tTrain Loss: 0.976\n",
            "\t Val. Loss: 0.948\n",
            "\n",
            "Validation loss has improved from 0.9475 to 0.9259\n",
            "Epoch: 06 | Epoch Time: 0m 26s\n",
            "\tTrain Loss: 0.939\n",
            "\t Val. Loss: 0.926\n",
            "\n",
            "Validation loss has improved from 0.9259 to 0.9026\n",
            "Epoch: 07 | Epoch Time: 0m 26s\n",
            "\tTrain Loss: 0.907\n",
            "\t Val. Loss: 0.903\n",
            "\n",
            "Validation loss has improved from 0.9026 to 0.8773\n",
            "Epoch: 08 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.876\n",
            "\t Val. Loss: 0.877\n",
            "\n",
            "Validation loss has improved from 0.8773 to 0.8286\n",
            "Epoch: 09 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.847\n",
            "\t Val. Loss: 0.829\n",
            "\n",
            "Validation loss has improved from 0.8286 to 0.7733\n",
            "Epoch: 10 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.817\n",
            "\t Val. Loss: 0.773\n",
            "\n",
            "Validation loss has improved from 0.7733 to 0.7657\n",
            "Epoch: 11 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.789\n",
            "\t Val. Loss: 0.766\n",
            "\n",
            "Validation loss has improved from 0.7657 to 0.7645\n",
            "Epoch: 12 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.765\n",
            "\t Val. Loss: 0.764\n",
            "\n",
            "Validation loss has improved from 0.7645 to 0.7079\n",
            "Epoch: 13 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.738\n",
            "\t Val. Loss: 0.708\n",
            "\n",
            "Validation loss has improved from 0.7079 to 0.7053\n",
            "Epoch: 14 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.712\n",
            "\t Val. Loss: 0.705\n",
            "\n",
            "Validation loss has improved from 0.7053 to 0.6757\n",
            "Epoch: 15 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.686\n",
            "\t Val. Loss: 0.676\n",
            "\n",
            "Validation loss has improved from 0.6757 to 0.6588\n",
            "Epoch: 16 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.667\n",
            "\t Val. Loss: 0.659\n",
            "\n",
            "Validation loss has improved from 0.6588 to 0.6302\n",
            "Epoch: 17 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.645\n",
            "\t Val. Loss: 0.630\n",
            "\n",
            "Validation loss has improved from 0.6302 to 0.6294\n",
            "Epoch: 18 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.625\n",
            "\t Val. Loss: 0.629\n",
            "\n",
            "Validation loss has improved from 0.6294 to 0.5954\n",
            "Epoch: 19 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.605\n",
            "\t Val. Loss: 0.595\n",
            "\n",
            "Validation loss has improved from 0.5954 to 0.5909\n",
            "Epoch: 20 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.587\n",
            "\t Val. Loss: 0.591\n",
            "\n",
            "Validation loss has improved from 0.5909 to 0.5644\n",
            "Epoch: 21 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.573\n",
            "\t Val. Loss: 0.564\n",
            "\n",
            "Validation loss has improved from 0.5644 to 0.5440\n",
            "Epoch: 22 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.554\n",
            "\t Val. Loss: 0.544\n",
            "\n",
            "Validation loss has improved from 0.5440 to 0.5336\n",
            "Epoch: 23 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.539\n",
            "\t Val. Loss: 0.534\n",
            "\n",
            "Validation loss has improved from 0.5336 to 0.5275\n",
            "Epoch: 24 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.523\n",
            "\t Val. Loss: 0.527\n",
            "\n",
            "Epoch: 25 | Epoch Time: 0m 26s\n",
            "\tTrain Loss: 0.514\n",
            "\t Val. Loss: 0.533\n",
            "\n",
            "Validation loss has improved from 0.5275 to 0.4928\n",
            "Epoch: 26 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.498\n",
            "\t Val. Loss: 0.493\n",
            "\n",
            "Validation loss has improved from 0.4928 to 0.4904\n",
            "Epoch: 27 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.485\n",
            "\t Val. Loss: 0.490\n",
            "\n",
            "Validation loss has improved from 0.4904 to 0.4824\n",
            "Epoch: 28 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.472\n",
            "\t Val. Loss: 0.482\n",
            "\n",
            "Validation loss has improved from 0.4824 to 0.4588\n",
            "Epoch: 29 | Epoch Time: 0m 27s\n",
            "\tTrain Loss: 0.462\n",
            "\t Val. Loss: 0.459\n",
            "\n"
          ]
        }
      ],
      "source": [
        "set_seed(42)\n",
        "create_dir(\"files\")\n",
        "\n",
        "X_train = sorted(glob(r\"/content/data/train/image/*\"))\n",
        "y_train = sorted(glob(r\"/content/data/train/mask/*\"))\n",
        "\n",
        "X_val = sorted(glob(r\"/content/data/test/image/*\"))\n",
        "y_val = sorted(glob(r\"/content/data/test/mask/*\"))\n",
        "\n",
        "height = 512\n",
        "width = 512\n",
        "img_size = (height, width)\n",
        "batch_size = 2\n",
        "epochs = 100\n",
        "lr = 1e-4\n",
        "chkpt_path = \"files/checkpoint.pth\"\n",
        "\n",
        "train_data = DriveDataset(X_train, y_train)\n",
        "val_data = DriveDataset(X_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset = train_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset = val_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model = UNET()\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "lr_schedule = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)\n",
        "loss_fn = DiceBCELoss()\n",
        "\n",
        "best_loss = float(\"inf\")\n",
        "loss_dict = {'train':[],\n",
        "             'val':[]}\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    start = time.time()\n",
        "    train_loss = train(model, train_loader, optimizer, loss_fn, device)\n",
        "    valid_loss = evaluate(model, val_loader, loss_fn, device)\n",
        "    loss_dict['train'].append(train_loss)\n",
        "    loss_dict['val'].append(valid_loss)\n",
        "\n",
        "    if valid_loss < best_loss:\n",
        "        hist = \"Validation loss has improved from {:2.4f} to {:2.4f}\".format(best_loss, valid_loss)\n",
        "        print(hist)\n",
        "        best_loss = valid_loss\n",
        "        torch.save(model.state_dict(), chkpt_path)\n",
        "\n",
        "    end = time.time()\n",
        "    epoch_mins, epoch_secs = train_time(start, end)\n",
        "    hist = f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\\n'\n",
        "    hist += f'\\tTrain Loss: {train_loss:.3f}\\n'\n",
        "    hist += f'\\t Val. Loss: {valid_loss:.3f}\\n'\n",
        "    print(hist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2b1mihsWgQC"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(y_true, y_pred):\n",
        "    \"\"\" Ground truth \"\"\"\n",
        "    y_true = y_true.cpu().numpy()\n",
        "    y_true = y_true > 0.5\n",
        "    y_true = y_true.astype(np.uint8)\n",
        "    y_true = y_true.reshape(-1)\n",
        "\n",
        "    \"\"\" Prediction \"\"\"\n",
        "    y_pred = y_pred.cpu().numpy()\n",
        "    y_pred = y_pred > 0.5\n",
        "    y_pred = y_pred.astype(np.uint8)\n",
        "    y_pred = y_pred.reshape(-1)\n",
        "\n",
        "    score_jaccard = jaccard_score(y_true, y_pred)\n",
        "    score_f1 = f1_score(y_true, y_pred)\n",
        "    score_recall = recall_score(y_true, y_pred)\n",
        "    score_precision = precision_score(y_true, y_pred)\n",
        "    score_acc = accuracy_score(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred)\n",
        "\n",
        "    return [score_jaccard, score_f1, score_recall, score_precision, score_acc, roc_auc]\n",
        "\n",
        "def mask_parse(mask):\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    mask = np.concatenate([mask, mask, mask], axis=-1)\n",
        "    return mask\n",
        "\n",
        "\n",
        "set_seed(42)\n",
        "create_dir(\"results\")\n",
        "\n",
        "test_x = sorted(glob(\"/content/data/test/image/*\"))\n",
        "test_y = sorted(glob(\"/content/data/test/mask/*\"))\n",
        "\n",
        "height = 512\n",
        "width = 512\n",
        "size = (height, width)\n",
        "checkpoint_path = \"files/checkpoint.pth\"\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = UNET()\n",
        "model = model.to(device)\n",
        "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "metrics_score = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
        "time_taken = []\n",
        "\n",
        "for i, (img, msk) in tqdm(enumerate(zip(test_x, test_y)), total=len(test_x)):\n",
        "    name = img.split(\"/\")[-1].split(\".\")[0]\n",
        "    image = cv2.imread(img, cv2.IMREAD_GRAYSCALE) ## (512, 512, 3)\n",
        "    image = cv2.resize(image, size)\n",
        "    x = np.expand_dims(image, axis=0)      ## (3, 512, 512)\n",
        "    x = x/255.0\n",
        "    x = np.expand_dims(x, axis=0)           ## (1, 3, 512, 512)\n",
        "    x = x.astype(np.float32)\n",
        "    x = torch.from_numpy(x)\n",
        "    x = x.to(device)\n",
        "\n",
        "    mask = cv2.imread(msk, cv2.IMREAD_GRAYSCALE)\n",
        "    mask = cv2.resize(mask, size)\n",
        "    y = np.expand_dims(mask, axis=0)\n",
        "    y = y/255.0\n",
        "    y = np.expand_dims(y, axis=0)\n",
        "    y = y.astype(np.float32)\n",
        "    y = torch.from_numpy(y)\n",
        "    y = y.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        start_time = time.time()\n",
        "        pred_y = model(x)\n",
        "        pred_y = torch.sigmoid(pred_y)\n",
        "        total_time = time.time() - start_time\n",
        "        time_taken.append(total_time)\n",
        "\n",
        "\n",
        "        score = calculate_metrics(y, pred_y)\n",
        "        metrics_score = list(map(add, metrics_score, score))\n",
        "        pred_y = pred_y[0].cpu().numpy()        ## (1, 512, 512)\n",
        "        pred_y = np.squeeze(pred_y, axis=0)     ## (512, 512)\n",
        "        pred_y = pred_y > 0.5\n",
        "        pred_y = np.array(pred_y, dtype=np.uint8)\n",
        "\n",
        "    ori_mask = mask_parse(mask)\n",
        "    pred_y = mask_parse(pred_y)\n",
        "    line = np.ones((size[1], 10, 3)) * 128\n",
        "\n",
        "    cat_images = np.concatenate(\n",
        "        [cv2.resize(cv2.imread(img, cv2.IMREAD_COLOR), size), line, ori_mask, line, pred_y * 255], axis=1\n",
        "    )\n",
        "    cv2.imwrite(f\"results/{name}.png\", cat_images)\n",
        "\n",
        "jaccard = metrics_score[0]/len(test_x)\n",
        "f1 = metrics_score[1]/len(test_x)\n",
        "recall = metrics_score[2]/len(test_x)\n",
        "precision = metrics_score[3]/len(test_x)\n",
        "acc = metrics_score[4]/len(test_x)\n",
        "roc_auc = metrics_score[5]/len(test_x)\n",
        "print(f\"Jaccard: {jaccard:1.4f} - F1: {f1:1.4f} - Recall: {recall:1.4f} - Precision: {precision:1.4f} - Acc: {acc:1.4f} - ROC-AUC: {roc_auc:1.4f}\")\n",
        "\n",
        "fps = 1/np.mean(time_taken)\n",
        "print(\"FPS: \", fps)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!zip -r results.zip results/"
      ],
      "metadata": {
        "id": "wrpRbF9gj7Di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.imread(img, cv2.IMREAD_COLOR).shape"
      ],
      "metadata": {
        "id": "LvtUasdwvJaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(epochs), loss_dict['train'])\n",
        "plt.plot(range(epochs), loss_dict['val'])"
      ],
      "metadata": {
        "id": "Q_ESgANLVsMD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}